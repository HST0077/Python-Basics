import requests  #url 읽어올때
from bs4 import BeautifulSoup
import lxml
import re

#구글에서 user agent string 검색해서 확인
headers={'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) # 접속에러가 생길 때

url='https://comic.naver.com/webtoon/list?titleId=675554'
res=requests.get(url)
res.raise_for_status() #연결 오류시 메시지 출력
soup=BeautifulSoup(res.text,'lxml')
carts=soup.find_all('a',string=re.compile('시즌4')) #a 태그중에서 '시즌4'라는 단어를 포함한 것들을 긁어온다. 
for cart in carts:
    print(cart.get_text()) #text 내용를 추출해준다. 
    link='https://comic.naver.com' + cart.get('href') # 태그에서 href 링크를 가져와서 붙여준다
    print(link)
    
